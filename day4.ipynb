{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYLCGEzQY-Xq"
      },
      "source": [
        "# Day 4 - Modelling with unsupervised learning & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5ys5bmrl-p-4"
      },
      "outputs": [],
      "source": [
        "#label manual terlebih dahulu untuk sentimen sebenarnya\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "utmb-HvX-qzO"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>content</th>\n",
              "      <th>clean1</th>\n",
              "      <th>clean2</th>\n",
              "      <th>clean3</th>\n",
              "      <th>tokens</th>\n",
              "      <th>clean_english</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@BangPitung_AJW @DokterTifa lah , ibu saya 74 ...</td>\n",
              "      <td>lah  ibu saya  thn  disuruh vaksin sampai di...</td>\n",
              "      <td>thn disuruh vaksin</td>\n",
              "      <td>thn suruh vaksin</td>\n",
              "      <td>['thn', 'suruh', 'vaksin']</td>\n",
              "      <td>Year told the vaccine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Oleh karena itu, Dewan Perwakilan Rakyat (DPRD...</td>\n",
              "      <td>oleh karena itu dewan perwakilan rakyat dprd k...</td>\n",
              "      <td>dewan perwakilan rakyat dprd kota semarang men...</td>\n",
              "      <td>dewan wakil rakyat dprd kota semarang dorong p...</td>\n",
              "      <td>['dewan', 'wakil', 'rakyat', 'dprd', 'kota', '...</td>\n",
              "      <td>Semarang City DPRD Representative Council Enco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>@_1507chan itu si pelaku menerobos barikade, s...</td>\n",
              "      <td>itu si pelaku menerobos barikade sudah nyubit...</td>\n",
              "      <td>si pelaku menerobos barikade nyubit dedek berh...</td>\n",
              "      <td>si laku terobos barikade nyubit dedek hasil jauh</td>\n",
              "      <td>['si', 'laku', 'terobos', 'barikade', 'nyubit'...</td>\n",
              "      <td>The barricade barricade was pinched by the lon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Bupati Karanganyar: Penolakan Vaksin PMK Sapi ...</td>\n",
              "      <td>bupati karanganyar penolakan vaksin pmk sapi w...</td>\n",
              "      <td>bupati karanganyar penolakan vaksin pmk sapi w...</td>\n",
              "      <td>bupati karanganyar tolak vaksin pmk sapi wajar</td>\n",
              "      <td>['bupati', 'karanganyar', 'tolak', 'vaksin', '...</td>\n",
              "      <td>Karanganyar Regent Rejects the PMK Cow Vaccine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>vaksin oh vaksin https://t.co/G2D1km3Vux</td>\n",
              "      <td>vaksin oh vaksin</td>\n",
              "      <td>vaksin oh vaksin</td>\n",
              "      <td>vaksin oh vaksin</td>\n",
              "      <td>['vaksin', 'oh', 'vaksin']</td>\n",
              "      <td>OH vaccine vaccine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                            content  \\\n",
              "0           0  @BangPitung_AJW @DokterTifa lah , ibu saya 74 ...   \n",
              "1           1  Oleh karena itu, Dewan Perwakilan Rakyat (DPRD...   \n",
              "2           2  @_1507chan itu si pelaku menerobos barikade, s...   \n",
              "3           3  Bupati Karanganyar: Penolakan Vaksin PMK Sapi ...   \n",
              "4           4           vaksin oh vaksin https://t.co/G2D1km3Vux   \n",
              "\n",
              "                                              clean1  \\\n",
              "0    lah  ibu saya  thn  disuruh vaksin sampai di...   \n",
              "1  oleh karena itu dewan perwakilan rakyat dprd k...   \n",
              "2   itu si pelaku menerobos barikade sudah nyubit...   \n",
              "3  bupati karanganyar penolakan vaksin pmk sapi w...   \n",
              "4                                  vaksin oh vaksin    \n",
              "\n",
              "                                              clean2  \\\n",
              "0                                 thn disuruh vaksin   \n",
              "1  dewan perwakilan rakyat dprd kota semarang men...   \n",
              "2  si pelaku menerobos barikade nyubit dedek berh...   \n",
              "3  bupati karanganyar penolakan vaksin pmk sapi w...   \n",
              "4                                   vaksin oh vaksin   \n",
              "\n",
              "                                              clean3  \\\n",
              "0                                   thn suruh vaksin   \n",
              "1  dewan wakil rakyat dprd kota semarang dorong p...   \n",
              "2   si laku terobos barikade nyubit dedek hasil jauh   \n",
              "3     bupati karanganyar tolak vaksin pmk sapi wajar   \n",
              "4                                   vaksin oh vaksin   \n",
              "\n",
              "                                              tokens  \\\n",
              "0                         ['thn', 'suruh', 'vaksin']   \n",
              "1  ['dewan', 'wakil', 'rakyat', 'dprd', 'kota', '...   \n",
              "2  ['si', 'laku', 'terobos', 'barikade', 'nyubit'...   \n",
              "3  ['bupati', 'karanganyar', 'tolak', 'vaksin', '...   \n",
              "4                         ['vaksin', 'oh', 'vaksin']   \n",
              "\n",
              "                                       clean_english  \n",
              "0                             Year told the vaccine   \n",
              "1  Semarang City DPRD Representative Council Enco...  \n",
              "2  The barricade barricade was pinched by the lon...  \n",
              "3  Karanganyar Regent Rejects the PMK Cow Vaccine...  \n",
              "4                                OH vaccine vaccine   "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('dataset/dataset_clean.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TY_DqHhV-6Us"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'label'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32me:\\Porto Data\\Sentiment Analysis\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[1;32me:\\Porto Data\\Sentiment Analysis\\env\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32me:\\Porto Data\\Sentiment Analysis\\env\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32me:\\Porto Data\\Sentiment Analysis\\day4.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Porto%20Data/Sentiment%20Analysis/day4.ipynb#ch0000003?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mvalue_counts()\n",
            "File \u001b[1;32me:\\Porto Data\\Sentiment Analysis\\env\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
            "File \u001b[1;32me:\\Porto Data\\Sentiment Analysis\\env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'label'"
          ]
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fToJXiNO-Rsk"
      },
      "source": [
        "## Modelling with textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoE7syVF-2IK"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBDTLBN7ie8q"
      },
      "outputs": [],
      "source": [
        "df['clean_english'] = df['clean_english'].astype('str')\n",
        "def get_polarity(text):\n",
        "  return TextBlob(text).sentiment.polarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQnIHaAW4RzH"
      },
      "outputs": [],
      "source": [
        "df['polarity'] = df['clean_english'].apply(get_polarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEbWFtDNX3DY"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W338vSLJifwX"
      },
      "outputs": [],
      "source": [
        "df['sentimen_textblob']=''\n",
        "df.loc[df.polarity>0,'sentimen_textblob']='positive'\n",
        "df.loc[df.polarity==0,'sentimen_textblob']='neutral'\n",
        "df.loc[df.polarity<0,'sentimen_textblob']='negative'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OCJV6nq4VXO"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nisye_uO_FSk"
      },
      "outputs": [],
      "source": [
        "df['sentimen_textblob'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pSlEiyj_EV3"
      },
      "outputs": [],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0azuygO4Y0y"
      },
      "outputs": [],
      "source": [
        "df.sentimen_textblob.value_counts().plot(kind='bar',title=\"Sentiment Analysis with Textblob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvnzmlbO-8MN"
      },
      "outputs": [],
      "source": [
        "df.sentimen_textblob.value_counts().plot(kind='pie',title=\"Sentiment Analysis with Textblob\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvWNUlir4fxN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExweE56P4fzz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhQP0ola4f2e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJrzZbSL_T6B"
      },
      "source": [
        "## Modelling with Vader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jszqXsTO4f4j"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.util import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh8vO8EZ4f62"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O3Dq_w84iaI"
      },
      "outputs": [],
      "source": [
        "df['scores'] = df['clean_english'].apply(lambda new_text: sid.polarity_scores(new_text))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT9h7u5j4wc9"
      },
      "outputs": [],
      "source": [
        "df['compound'] = df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
        "df['sentimen_vader']=''\n",
        "df.loc[df.compound>0,'sentimen_vader']='positive'\n",
        "df.loc[df.compound==0,'sentimen_vader']='neutral'\n",
        "df.loc[df.compound<0,'sentimen_vader']='negative'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9UW97F24yta"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t19KICgY_xZu"
      },
      "outputs": [],
      "source": [
        "df['sentimen_vader'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXNSXgcyZKhx"
      },
      "outputs": [],
      "source": [
        "df['sentimen_textblob'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2mnMhCPZOHy"
      },
      "outputs": [],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_CykyBk411X"
      },
      "outputs": [],
      "source": [
        "df.sentimen_vader.value_counts().plot(kind='bar',title=\"Sentiment Analysis with Vader\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BAaBLdkAMdf"
      },
      "outputs": [],
      "source": [
        "df.sentimen_vader.value_counts().plot(kind='pie',title=\"Sentiment Analysis with Vader\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsYhYhMg5oEZ"
      },
      "outputs": [],
      "source": [
        "df.to_csv('/content/drive/MyDrive/mini-bootcamp/hasil-2.csv', index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQilc0PH5oKF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gst3AncfAOrT"
      },
      "source": [
        "## Accuracy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKDMLwic9hxx"
      },
      "source": [
        "### accuracy textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnQj5UyW5oMp"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BviCLtq35qP_"
      },
      "outputs": [],
      "source": [
        "accuracy_score(df['label'],df['sentimen_textblob'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BnZJ13954R3"
      },
      "outputs": [],
      "source": [
        "print(classification_report(df['label'],df['sentimen_textblob']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpMAiIIC59iO"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix Testing\n",
        "cm_pred = confusion_matrix(df['label'],df['sentimen_textblob'])\n",
        "print(cm_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vludIs8A6ApD"
      },
      "outputs": [],
      "source": [
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_cm_pred = pd.DataFrame(cm_pred, index = [i for i in [\"Negative\", \"Neutral\", \"Positive\"]],\n",
        "                          columns = [i for i in [\"Negative\", \"Neutral\", \"Positive\"]])\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm_pred, annot=True, cbar=False, fmt=\"d\")\n",
        "plt.savefig('/content/drive/MyDrive/mini-bootcamp/confusion_matrix_textblob.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4uXsy9U-Pgb"
      },
      "source": [
        "### accuracy vader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgP7UaU_-S-U"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVKcV64S-VZl"
      },
      "outputs": [],
      "source": [
        "accuracy_score(df['label'],df['sentimen_vader'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kbc9vdMe-XzT"
      },
      "outputs": [],
      "source": [
        "print(classification_report(df['label'],df['sentimen_vader']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq0wrhth-a3m"
      },
      "outputs": [],
      "source": [
        "#Confusion Matrix Testing\n",
        "cm_pred = confusion_matrix(df['label'],df['sentimen_vader'])\n",
        "print(cm_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7kEnEUlHWqx"
      },
      "outputs": [],
      "source": [
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_cm_pred = pd.DataFrame(cm_pred, index = [i for i in [\"Negative\", \"Neutral\", \"Positive\"]],\n",
        "                          columns = [i for i in [\"Negative\", \"Neutral\", \"Positive\"]])\n",
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.heatmap(df_cm_pred, annot=True, cbar=False, fmt=\"d\")\n",
        "plt.savefig('/content/drive/MyDrive/mini-bootcamp/confusion_matrix_vader.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4dmLIrJ6Fen"
      },
      "outputs": [],
      "source": [
        "df.to_csv('/content/drive/MyDrive/mini-bootcamp/hasilcoba.csv', index=None)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "day4.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "37f6a94d0a68daebf1f32b2dc401540bd40931aca38f19e9fc25365b6f4d8746"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
